{"meta":{"title":"老树","subtitle":"静坐常事已过,闲谈莫论人非.","description":"静坐常事已过,闲谈莫论人非.","author":"老树","url":"http://yoursite.com"},"pages":[{"title":"about","date":"2017-11-18T13:45:40.000Z","updated":"2017-11-18T13:45:40.000Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":""}],"posts":[{"title":"异常检测Isolation Forest","slug":"iForest","date":"2018-06-03T03:21:00.000Z","updated":"2018-06-03T03:20:08.000Z","comments":true,"path":"2018/06/03/iForest/","link":"","permalink":"http://yoursite.com/2018/06/03/iForest/","excerpt":"","text":"一、目的挖掘异常数据，在线异常检测。算法来源08年的一篇论文《Isolation Forest》(https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf)，由南京大学周志华教授和澳大利亚莫纳什大学的两位教授Fei Tony Liu, Kai Ming Ting三人共同完成。在2011年又发表了《Isolation-based Anomaly Detection》(https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/tkdd11.pdf)。 算法基础主要是异常数据的两个特征：1）异常数据只占很少量 2）异常数据特征值和正常数据差别很大。因此，构建二叉树型结构的时候，异常数据离根更近，而正常数据离根更远。 二、算法原理与随机森林由大量决策树组成一样，iForest森林也由大量的树组成。iForest中的树叫isolation tree，简称iTree。iTree树和决策树不太一样，其构建过程也比决策树简单，因为其中就是一个完全随机的过程。具体步骤： 假设数据集有N条数据，构建一颗iTree时，从N条数据中均匀抽样(一般是无放回抽样)出ψ个样本出来，作为这颗树的训练样本； 在样本中，随机选一个特征，并在这个特征的所有值范围内(最小值与最大值之间)随机选一个值，对样本进行二叉划分，将样本中小于该值的划分到节点的左边，大于等于该值的划分到节点的右边； 对于左右两边的子树，分别重复步骤2)； 直到达到终止条件。终止条件：1.一个数据不能再分了(即只剩下一个数据，或者剩下数据都相同)；2. 树的高度达到log2(ψ)。注：log2(ψ)值近似于树的平均深度，因为只需要关注低于平均高度的数据点，而不需要树进行完全生成。 构建完所有的iTree树，使用测试集进行测试。测试过程：把测试数据在iTree树上沿对应的条件分支往下走，直到达到叶子节点，并记录这过程中经过的路径长度h(x)—所走过的边的数量。注：iTree能有效检测异常的假设是：异常点一般都是非常稀有的，在iTree中会很快被划分到叶子节点。 计算每条待测数据的异常分数(Anomaly Score)。公式 S(x,n)=2的指数(-(h(x)/c(n)) c(n)=2H(n−1)−(2(n−1)/n) 其中H(k)=ln(k)+ξ，ξ=0.5772156649为欧拉常数 s(x,n)就是记录x在由n个样本的训练数据构成的iTree的异常指数，s(x,n)取值范围为[0,1]。欧拉常数值为0.5772156649，对于s(x,n)： 1) 如果分数越接近1，其是异常点的可能性越高； 2) 如果分数都比0.5要小，那么基本可以确定为正常数据； 3) 如果所有分数都在0.5附近，那么数据不包含明显的异常样本。 三、算法分析1.算法特点。本算法的特点区别现有算法在于：现有算法主要是基于正常数据构建数据模型，将不符合该模型的数据定义为异常数据。而本算法不需要对正常的数据构建模型，能够快速的找出异常数据。 2.高维度数据。如特征包含多个维度，算法不能将所有的属性都用上，此时需要选择有价值的属性，使用峰度系数Kurtosis来选择。 3.算法参数设置 1）树的多少。实验发现，在100颗树的时候，路径的长度就已经覆盖得比较好了，因此选100颗足够。 2）采样的多少。采样，是为了更好的将正常数据和异常数据分离开来。有别于其它模型，采样数据越多，反面会降低iForest识别异常数据的能力。因为，通常使用256个样本。 4.算法优势 1）算法对内存要求很低，且处理速度很快，其时间复杂度也是线性的； 2） 处理高维数据和大数据，可以在线预测； 3）iForest既能发现群异常数据，也能发现散点异常数据。同时也能处理训练数据中不包含异常数据的情况。 四、算法实现算法的实现是基于python下的 scikit-learn 算法包直接 from sklearn.ensemble import IsolationForest 导入，具体的参数配置： n_estimators: 默认为100，配置iTree树的多少 max_samples: 默认为265，配置采样大小 max_features: 默认为全部特征，对高维数据，可以只选取部分特征 Java算法实现 https://github.com/JeemyJohn/AnomalyDetection","categories":[{"name":"异常检测算法","slug":"异常检测算法","permalink":"http://yoursite.com/categories/异常检测算法/"}],"tags":[{"name":"异常、检测、Isolation Forest、iTree","slug":"异常、检测、Isolation-Forest、iTree","permalink":"http://yoursite.com/tags/异常、检测、Isolation-Forest、iTree/"}],"keywords":[{"name":"异常检测算法","slug":"异常检测算法","permalink":"http://yoursite.com/categories/异常检测算法/"}]},{"title":"朴素贝叶斯分类算法","slug":"bayes","date":"2018-05-27T01:21:00.000Z","updated":"2018-05-27T01:36:12.000Z","comments":true,"path":"2018/05/27/bayes/","link":"","permalink":"http://yoursite.com/2018/05/27/bayes/","excerpt":"","text":"一 理解 在我的理解中，朴素贝叶斯比较简单，但却又不知道该如何表达这种简单之处，所以就一直思考通过某种方式出来。 朴素：本意是简朴、不奢侈。在此则表示外在条件简单，如要求所有的特征之间是相互独立的。 贝叶斯：顾名思义，就是通过贝叶斯定理来进行分类。 二 原理朴素贝叶斯分类算法的核心就是贝叶斯定理，理解了贝叶斯理解，算法就自然而然理解了。 第一步：首先从贝叶斯公式开始理解。 P(B|A) = P(A|B) P(B)/ P(A) =&gt; P(分类|特征) = P(特征|分类) P(分类)/ P(特征) 通过条件概率公式求得分类结果。 第二步：将朴素概念加入到贝叶斯中去。特征之间相互独立 P(A|B) = P(A1|B) P(A2|B) P(A3|B) P(A4|B) ...... P(An|B) 这个公式可以通过训练数据求得概率，又涉及到中心极限定理：频率=概率 第三步：在求得各个概率后，带入到上式中，既可以求得概率，如果大于0.5，即属于该分类，反正属于反分类。 三 总结整个过程计算简单、逻辑易于理解，算法的开销也相对较低； 引入了朴素概念，在现实中各个特征之间相互独立往往不是成立的，如果特征之间关联较大，分类效果不好； from sklearn.naive_bayes import GaussianNB from sklearn.metrics import accuracy_score def bayes_classify(features_train, labels_train, features_test, labels_test): x = features_train y = labels_train clf = GaussianNB() clf.fit(x, y) pred = clf.predict(features_test) return accuracy_score(labels_test, pred)","categories":[{"name":"分类算法","slug":"分类算法","permalink":"http://yoursite.com/categories/分类算法/"}],"tags":[{"name":"朴素、bayes","slug":"朴素、bayes","permalink":"http://yoursite.com/tags/朴素、bayes/"}],"keywords":[{"name":"分类算法","slug":"分类算法","permalink":"http://yoursite.com/categories/分类算法/"}]},{"title":"Bagging和Boosting方法","slug":"baggingAndBoosting","date":"2018-05-26T12:21:00.000Z","updated":"2018-05-26T11:54:36.000Z","comments":true,"path":"2018/05/26/baggingAndBoosting/","link":"","permalink":"http://yoursite.com/2018/05/26/baggingAndBoosting/","excerpt":"","text":"俗语说：“众人拾柴火焰高”，Bagging方法和Boosting方法的原理与此类似，都是将各种分类方法按不同的策略进行组合，整合多个模型的优点提高整体的精确度。也就是常说的将弱分类器组合成强分类器的思想。 一 概念1.1 Bagging方法Bagging方法，即称为bootstrap aggregating。本质思想是使用同一个算法对同一个训练集进行随机有放回的抽样，训练得到多个模型，在基于这类模型进行分类。其具体思路： 训练集，参数n和k。对于给定的原始样本，随机有放回从样本中抽取n个样本作为训练集，每次抽取时原始样本的数量相等，抽取k次，即得到k个n大小的训练集。当然，这个k个训练集之间都是相互独立的。 模型，参考k。利用具体的方法(方法的确定需要与具体的问题结合选择)，对k个训练集进行训练得到k个模型。 分类结果组合策略。将待分类的数据通过k个模型得到k分类结果，选择合适的结果组合策略，如少数服从多数、均值等来确定最终的结果。 整个过程核心点：随机有放回抽样、结果组合策略 1.2 Boosting方法boosting方法的本质思想是引入了样本的权重，同时依赖于上一次的训练结果。具体思路： 训练集。训练集大小是不变的，变化的只是训练集中样本样例的权重，权重的变化依赖于上一次模型的分类结果，即提高对在上一次分类错误样本的权重，减少在上一次分类正确样本样例的权重。 模型组合。可以将模型进行线性组合，也可以直接组合等组合策略。 二 区别二者的区别可以从以下几个方面来说：训练集选择、样本中样例权重、模型组合策略、性能等方面。 训练集选择。 Bagging方法：训练集是在样本中随机有放回选择出来的 Boosting方法：训练集一直不变 样本中样例权重 Bagging方法：训练集中样本样例的权重相等 Boosting方法：训练集样本样例的权重不相同，权重调整策略是依据上一轮的分类模型结果 模型组合策略 Bagging方法：每个模型的权重是相等的组合在一起 Boosting方法：每个模型的权重不等，模型的误差越小，权重越大 算法性能 同样的训练集和同样的方法前提下 Bagging方法：各个模型可以并行计算，相互不影响 Boosting方法：当前模型需要依赖上一次模型的结果进行调整，串行执行 策略+模型 Bagging方法：Bagging+决策树=随机森林 Boosting方法：AdaBoost+决策树=提升树","categories":[{"name":"分类算法","slug":"分类算法","permalink":"http://yoursite.com/categories/分类算法/"}],"tags":[{"name":"Bagging、Boosting","slug":"Bagging、Boosting","permalink":"http://yoursite.com/tags/Bagging、Boosting/"}],"keywords":[{"name":"分类算法","slug":"分类算法","permalink":"http://yoursite.com/categories/分类算法/"}]},{"title":"随机森林算法","slug":"randomForest","date":"2018-05-26T10:21:00.000Z","updated":"2018-06-03T03:24:05.000Z","comments":true,"path":"2018/05/26/randomForest/","link":"","permalink":"http://yoursite.com/2018/05/26/randomForest/","excerpt":"","text":"一 理解随机森林是通过集成学习的思想将多多个决策树集成的算法，涉及到集成学习思想。可以从两个角度来理解：随机+森林。森林就是一颗颗树组成的，随机 则是特征维度值选择和每棵树的生成没有剪枝过程。 二 概念随机森林看起来是很好理解，但是要完全搞明白它的工作原理，需要很多机器学习方面相关的基础知识。在本文中，我们简单谈一下，而不逐一进行赘述，如果有同学不太了解相关的知识，可以参阅其他博友的一些相关博文或者文献。 1）信息、熵以及信息增益的概念 引用香农的话来说，信息是用来消除随机不确定性的东西。当然这句话虽然经典，但是还是很难去搞明白这种东西到底是个什么样，可能在不同的地方来说，指的东西又不一样。对于机器学习中的决策树而言，如果带分类的事物集合可以划分为多个类别当中.熵是用来度量不确定性的，当熵越大，X=xi的不确定性越大，反之越小。对于机器学习中的分类问题而言，熵越大即这个类别的不确定性更大，反之越小。 信息增益在决策树算法中是用来选择特征的指标，信息增益越大，则这个特征的选择性越好。 2）决策树 决策树是一种树形结构，其中每个内部节点表示一个属性上的测试，每个分支代表一个测试输出，每个叶节点代表一种类别。常见的决策树算法有C4.5、ID3和CART。 3）集成学习 集成学习通过建立几个模型组合的来解决单一预测问题。它的工作原理是生成多个分类器/模型，各自独立地学习和作出预测。这些预测最后结合成单预测，因此优于任何一个单分类的做出预测。 随机森林是集成学习的一个子类，它依靠于决策树的投票选择来决定最后的分类结果。 三 随机森林3.1 样本抽样随机森林在构建过程中，假设训练集大小为N，其抽样方法为 随机有放回的抽样 大小为n的训练子集作为每棵树的的训练集。怎么来理解随机有放回的抽样呢？ 随机：需要反过来看待，即如果不是随机的，那随机森林中所有的树最后都是一样的，那就没必要使用集成学习了。 有放回：预测的最终结果是将对所有森林中的树的预测结果进行比较，选择类别较大的作为最终结果。在这个选择过程中，就需要有共性的信息才能有选择，这就要求训练集中存在着共性。 3.2 特征确定对于训练集，都有相同的特征树M，现在需要确定一个值m&lt;&lt;M,这个m值的确定方式有 logN，N/3，sqrtN，N四种类型。每次树进行分裂时，从这m个特征中选择最优的； m值的影响：如果m值偏大，导致树的相关性和分类能力会增大；m值偏小时，会导致树的相关性和分类能力减小。 m值的确定：使用袋外错误率来评估。袋外错误率的定义：在选择n个训练集得到一棵树后，在利用剩余的训练集作为测试集，计算分类错误率，即为袋外错误率。在这个过程中，需要大量的计算K折交叉验证。 3.3 特点 能够运用在数据集上 能够处理高纬度样本数据，不需要降维 能够评估特格特征的重要程度 对缺失值不太敏感 3.4 算法的选择常见的决策树算法有C4.5、ID3和CART(分类回归树) 参数 max_features: 单个决策树的最大特征量 n_estimators: 建立子树的数量 min_sample_leaf:最小叶子节点数量","categories":[{"name":"分类算法","slug":"分类算法","permalink":"http://yoursite.com/categories/分类算法/"}],"tags":[{"name":"随机森林、RandomForest","slug":"随机森林、RandomForest","permalink":"http://yoursite.com/tags/随机森林、RandomForest/"}],"keywords":[{"name":"分类算法","slug":"分类算法","permalink":"http://yoursite.com/categories/分类算法/"}]},{"title":"我说你听","slug":"spreakListen","date":"2018-04-26T12:21:00.000Z","updated":"2018-05-26T12:04:47.000Z","comments":true,"path":"2018/04/26/spreakListen/","link":"","permalink":"http://yoursite.com/2018/04/26/spreakListen/","excerpt":"","text":"我说闯过黑夜就是白天白天却不见你的影子我说穿过千山就在眼前眼前却不见你的身影 在黑夜里迎赶白天能和你享受夜晚的每一瞬间在千山间垮至眼前能和你见证幸福的每一瞬间 原来，黑夜里也能和你数天上的星星原来，千山间也能和你传此间的情谊 那就在黑夜里放纵那就在千山间奔腾因为这一切都在你我心里","categories":[{"name":"思想","slug":"思想","permalink":"http://yoursite.com/categories/思想/"}],"tags":[{"name":"听说","slug":"听说","permalink":"http://yoursite.com/tags/听说/"}],"keywords":[{"name":"思想","slug":"思想","permalink":"http://yoursite.com/categories/思想/"}]},{"title":"若遇爱,请好好爱","slug":"pleaseLove","date":"2017-11-18T02:08:00.000Z","updated":"2017-12-17T13:26:27.000Z","comments":true,"path":"2017/11/18/pleaseLove/","link":"","permalink":"http://yoursite.com/2017/11/18/pleaseLove/","excerpt":"文 / 树儿我们都是尘世中一朵寂寞的烟火。与无涯的岁月里，透视着人间百态的繁复。也成全着生命中必然的遇见。也许，时光的两岸，唯有不辜负光阴，不违背心意，就是安稳与静好的妥帖。","text":"文 / 树儿我们都是尘世中一朵寂寞的烟火。与无涯的岁月里，透视着人间百态的繁复。也成全着生命中必然的遇见。也许，时光的两岸，唯有不辜负光阴，不违背心意，就是安稳与静好的妥帖。 只一个转身，便已踏进冬的门楣。我从一卷遗落的风声里，看忘川的心事，散落在潇潇秋色中。我们都是这个尘世孤独的孩子，在各自的光阴里自渡。青白的锁骨纠结着无郁的忧伤，明媚的阳光埋藏着冰封的温度，而疼痛以隐秘的方式在生长。 其实，这本就是个无常的世界，不是所有的相遇都会有个完满的结局，一阙花间词的幽怨换不来笛声的明亮。 所幸，还有文字，还有友情，让我们可以在烟火的世界里宁静的皈依。用温暖，写意花开的记忆。 墨已入水， 渡一池青花；风月花鸟，一笑尘缘了，刘珂矣《半壶纱》里的一句。彼时，循环着这首曲子，于无言处听一曲阳春白雪。万千情意，藏檀香袅绕；一世相思，埋一声佛号。谁与烟雨楼外舞尽尘世繁华？谁在时光的韵脚里落寞了红尘浅殇？岁月无挽，都将老去，叹只叹，情字斑驳，唯以时间与等待来给予成全。 然，一路收纳于心的感念与温暖却铺成了别样的精致。落日长烟，暮染凉秋，孤独尽处，落款是清欢。 也许，生活就是这样，总是会带来一些，又带走一些。而就在这来去之间，只把，朝朝暮暮镌刻成明媚如初。那是烟火的味道，也是幸福的味道。 有时候会想，这一世的山高水长，走过那么多的路，看过那么多的人，谁会比谁更清醒，谁又会在午夜梦回时想起谁？我们都是沧海中一贝，一次次的在人群中相遇，拥有，别离。小禅说：所有的往事不过如此，所谓的刻骨铭心与一生一世，有的时候，只是往事中用来书写的一笔而已。 想来确实如此，那些自以为是的始至不忘，到头来模糊的只剩下影子，甚或连影子都是多余的。我们的内心，早已在世俗中被修炼的百毒不侵，风里雨里，生命航线一直向前，从不会因谁，而改变。也许，这就是生活的常态，渐渐的安于得失，安于疏离，安于见与不见。在孤独里，依旧会清欢，而生命也因着不圆满才有了期盼。 我们都是人间的旅者，背负着宿命的因缘，人人都活的不易。莲心本清苦，却只将欢喜与馨香与人分享，留着酸涩与痛楚独自回味。人生若平静待世，温良静安，别去浮华，便是一帘极致的优雅。岁月赋予我们的应是宁和，善解与感恩。 其实，太多的时候，我们总是希望一切都简简单单的。就如，我爱你，你也爱我，相拥着两个人的温暖。幸福着，一直在一起，一直。 一念长安。岁月不老。若遇爱，请好好爱，时光苍绿，是因为我们都相信真情。 “若你温柔待人，岁月必定也会待你温柔。”看到的一句话，很喜欢。漫漫时光，水如月凉，盈亏都是不随人意而流转的。这本就是个因果的世界，人与人之间唯有相惜，才会相暖。 缘，不在深浅；情，不在远近。多少鲜衣怒马，最后都会归于平淡。唯独一份细水长流的相伴是水墨青花的句点，演绎着这世间最美的情谊.世界可大可小，只在一颗心与另一颗心之间，串起冬天枝头上的斑斓，温暖着美好的本意。相信，时光之外，红尘之内，皆似暖，皆是暖。 芸芸红尘，故事里的故事，每一天都在重复上演。也许，不是所有的相遇，都可以守候成流年的风景。其实，世间太多的真相，不必去刻意寻找答案。就如，人群中，你来了，去了；去了，又来了，其实沒有什么区别。 我只珍藏我的一片山河，安放我的深情和一朵落花的忧伤。在岁月的香息里，静寂相守，浅笑嫣然，如此，就好。 其实，很多事，再回眸，已是莞尔。岁月烹煮着光阴的乱红，而我们也应当学会，与每一季的温暖去深情相拥。 学着，不去埋怨生活，不去窖藏忧伤。看淡人世恩怨，与风雨中舞出最美的笑容，便是岁月无悔的从容。 其实，生活就是嵌在掌纹里的朴实，穿过时光的长廊，那些明媚而生动的善暖都是一生的珍贵。而随缘偶得的同行，是安暖更是清喜。相信，爱，从未遗忘，陪伴便是长情。 如果可以，愿执喧嚣深处的宁静，依着沁满心扉的静好，任敛了暗香的心事合在掌心。那是绘着烟雨的美丽，在一场荼蘼的花事里兀自销魂，只一抹婉约，便叩响了温情的牵念。 佛说，生命中的很多东西是可遇不可求的，强求的得不到，不曾被期待的却会不期而至。就像，有些缘分是用来相遇的，有些情感是用来怀念的，随缘，顺缘，以一颗清净心看菩提世界，以一颗随喜心看万物变幻。也许，我们只是在旅途中相伴彼此一程的同路人，记住那些温暖，记住那些爱。即使，有一天擦肩而过，也不悔这一程的美好。 时光在走，留给我们越来越多的回忆，或甜蜜，或忧伤，或也不过是一抹微笑的影子。只是，依然相信，有一种情感不会在光阴的流转里褪色。经年之后，会开出一朵叫做回忆的花。 日子浅浅流动，只想，面朝阳光，与岁月温柔相待。因为相信，在薄情的世界里，自有深情与共。 这个冬天，且与温暖同行。愿时光与我们，都无恙。","categories":[{"name":"思想","slug":"思想","permalink":"http://yoursite.com/categories/思想/"}],"tags":[{"name":"若遇爱 好好爱","slug":"若遇爱-好好爱","permalink":"http://yoursite.com/tags/若遇爱-好好爱/"}],"keywords":[{"name":"思想","slug":"思想","permalink":"http://yoursite.com/categories/思想/"}]},{"title":"Azkaban3.0安装教程","slug":"azkaban3.0Install","date":"2017-05-07T06:16:00.000Z","updated":"2017-12-17T13:22:55.000Z","comments":true,"path":"2017/05/07/azkaban3.0Install/","link":"","permalink":"http://yoursite.com/2017/05/07/azkaban3.0Install/","excerpt":"本次安装azkaban的版本3.20.0-5,相对版本2.5有部分变化，此次安装two-server模式。","text":"本次安装azkaban的版本3.20.0-5,相对版本2.5有部分变化，此次安装two-server模式。In version 3.0 we provide three modes: the stand alone “solo-server” mode, the heavier weight two server mode and distributed multiple-executor mode. The following describes the differences between the two modes. 三种模式 solo-server模式：exec进程和web进程为同一个进程，存放元数据的数据库为H2； two-server模式：与之前的单机版本类似，exec进程和web进程分开，存放元数据的数据库为mysql； multiple-executor模式：exec进程和web进程在不同的机器上，存放元数据的数据库为mysql。 安装准备 Azkaban官网 软件下载地址 官方插件地址 官方文档地址 安装过程 下载。git clone https://github.com/azkaban/azkaban.git 得到文件夹 azkaban； 编译。执行命令cd azkaban，在该目录下执行 ./gradlew installDist 生成一系列文件 拷贝。另新建目录mkdir azkaban-3.20.0，执行 1234567cp azkaban/azkaban-exec-server/build/distributions/azkaban-exec-server-3.20.0-5-g28fc94e7.tar.gz azkaban-3.20.0cp azkaban/azkaban-web-server/build/distributions/azkaban-web-server-3.20.0-5-g28fc94e7.tar.gz azkaban-3.20.0cp azkaban/azkaban-sql/build/distributions/azkaban-sql-3.20.0-5-g28fc94e7.tar.gz azkaban-3.20.0cd azkaban-3.20.0tar -zvxf azkaban-exec-server-3.20.0-5-g28fc94e7.tar.gztar -zvxf azkaban-web-server-3.20.0-5-g28fc94e7.tar.gztar -zvxf azkaban-sql-3.20.0-5-g28fc94e7.tar.gz 创建azkaban元数据库。在Mysql数据库中创建元数据。同时从外部导入mysql jar包到azkaban-exec-server-3.0.0/extlib/和azkaban-web-server-3.0.0/extlib/ 12345671) 以root用户登录mysql2) CREATE DATABASE azkaban;3) CREATE USER &apos;azkaban&apos;@&apos;%&apos; IDENTIFIED BY &apos;azkaban&apos;;4) GRANT SELECT,INSERT,UPDATE,DELETE ON azkaban.* to &apos;azkaban&apos;@&apos;%&apos; WITH GRANT OPTION;5) flush privileges;6) use azkaban;7) source /home/hadoop/azkaban/azkaban-sql-3.20.0-5-g28fc94e7/create-all-sql-3.0.0.sql 配置azkaban-web-server。执行mv azkaban-exec-server-3.20.0-5-g28fc94e7 azkaban-exec-server-3.20.0-5,且在该目录下执行keytool -keystore keystore -alias jetty -genkey -keyalg RSA生成keystore文件，配置SSL。 12341) cd azkaban-exec-server-3.20.0-5，此目录如下bin conf extlib lib plugins projects temp目录(如该目录下没有相应的文件夹，则直接在azkaban-solo-server目录下拷贝就行)。2) conf目录下存放azkaban.properties global.properties log4j.properties三个文件3) extlib目录下存放mysql-connector-java-5.1.41-bin.jar连接mysql的Java驱动包4) plugins目录下存放jobtypes/commonprivate.properties文件 azkaban.properties #Azkaban default.timezone.id=America/Los_Angeles #Azkaban JobTypes Plugins azkaban.jobtype.plugin.dir=plugins/jobtypes #Loader for projects executor.global.properties=conf/global.properties azkaban.project.dir=projects #Azkaban元数据库信息 database.type=mysql mysql.port=3306 mysql.host=localhost mysql.database=azkaban mysql.user=azkaban mysql.password=azkaban mysql.numconnections=100 #Azkaban Executor settings executor.maxThreads=50 executor.port=12321 executor.flow.threads=30 #JMX stats jetty.connector.stats=true executor.connector.stats=true #uncomment to enable inmemory stats for azkaban #executor.metric.reports=true #executor.metric.milisecinterval.default=60000 配置azkaban-exec-server.配置对应conf/azkaban.properties conf/global.properties conf/log4j.properties log4j.properties log4j.rootLogger=INFO,C log4j.appender.C=org.apache.log4j.ConsoleAppender log4j.appender.C.Target=System.err log4j.appender.C.layout=org.apache.log4j.PatternLayout log4j.appender.C.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n 启动。启动web-server和exec-server，执行bin/azkaban-executor-start.sh和bin/azkaban-web-start.sh命令。创建Project，两种方式：web界面创建和通过API创建（方法）。插件安装 git clone https://github.com/azkaban/azkaban-plugins.git cd到对应目录下 执行ant","categories":[{"name":"技术","slug":"技术","permalink":"http://yoursite.com/categories/技术/"}],"tags":[{"name":"Azkaban 大数据","slug":"Azkaban-大数据","permalink":"http://yoursite.com/tags/Azkaban-大数据/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"http://yoursite.com/categories/技术/"}]}]}